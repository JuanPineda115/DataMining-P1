{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidad del Valle de Guatemala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto 1: Análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laura Tamath\t19365 |     Andrea Amaya 19357 |\n",
    "Brandon Hernández\t 19376 |\t\tMartin Amado\t19020 |   Juan Pablo Pineda 19087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pyreadstat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import pyclustertend \n",
    "import random\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, confusion_matrix\n",
    "import sklearn.preprocessing\n",
    "from sklearn.cluster import Birch, KMeans, AgglomerativeClustering, MiniBatchKMeans\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = ['dep_reg', 'mun_reg', 'mon_reg', 'year_reg', 'dep_occu','mun_occu','area_geog','sex_death','day_occu',\n",
    "'month_occu','year_occu','part_type','birth_class','via_part','weeks_ges', 'mother_age' ,'mom_country_res','mom_dep_res',\n",
    "'mom_mun_resi', 'mom_group', 'mom_civil_status', 'mom_nationality', 'mom_scholarship', 'mom_occupation', 'cause_death',\n",
    "'assistance_received', 'site_occu', 'total_children', 'total_dead_children', 'total_living_children']\n",
    "\n",
    "quan_vars = ['weeks_ges', 'mother_age', 'total_children', 'total_dead_children', 'total_living_children']\n",
    "qual_vars = []\n",
    "for var in var_names: \n",
    "  if var not in quan_vars: qual_vars.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(data_frame, to_remove, is_quali=True):\n",
    "  df = data_frame.copy()\n",
    "  all_vars = var_names[:]\n",
    "  remove_vars = to_remove[:]\n",
    "\n",
    "  for var in remove_vars: all_vars.remove(var)\n",
    "  df.columns = all_vars\n",
    "  for var in remove_vars:\n",
    "    df[var] = np.full(len(df.index), np.nan if is_quali else 0)\n",
    "  return df.reindex(sorted(df.columns), axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = pd.read_spss('./data/db_2009.sav')\n",
    "df_2010 = pd.read_spss('./data/db_2010.sav')\n",
    "df_2011 = pd.read_spss('./data/db_2011.sav')\n",
    "df_2012 = pd.read_spss('./data/db_2012.sav')\n",
    "df_2013 = pd.read_spss('./data/db_2013.sav')\n",
    "df_2014 = pd.read_spss('./data/db_2014.sav')\n",
    "df_2015 = pd.read_spss('./data/db_2015.sav')\n",
    "df_2016 = pd.read_spss('./data/db_2016.sav')\n",
    "df_2017 = pd.read_spss('./data/db_2017.sav')\n",
    "df_2018 = pd.read_spss('./data/db_2018.sav')\n",
    "df_2019 = pd.read_spss('./data/db_2019.sav')\n",
    "df_2020 = pd.read_spss('./data/db_2020.sav')\n",
    "\n",
    "# Filter data\n",
    "remove_2009 = ['via_part', 'mom_country_res', 'mom_scholarship']\n",
    "remove_2010_2011 = ['mom_country_res']\n",
    "remove_2012_2013_2014 = ['year_occu']\n",
    "remove_2018_2019_2020 = ['area_geog']\n",
    "\n",
    "df_2009 = filter_df(df_2009, remove_2009)\n",
    "df_2009['year_occu'] = np.full(len(df_2009.index), '2009')\n",
    "df_2009['year_reg'] = np.full(len(df_2009.index), '2009')\n",
    "df_2010 = filter_df(df_2010, remove_2010_2011)\n",
    "df_2011 = filter_df(df_2011, remove_2010_2011)\n",
    "df_2012 = filter_df(df_2012, remove_2012_2013_2014)\n",
    "df_2012['year_occu'] = np.full(len(df_2012.index), '2012')\n",
    "df_2013 = filter_df(df_2013, remove_2012_2013_2014)\n",
    "df_2013['year_occu'] = np.full(len(df_2013.index), '2013')\n",
    "df_2014 = filter_df(df_2014, remove_2012_2013_2014)\n",
    "df_2014['year_occu'] = np.full(len(df_2014.index), '2014')\n",
    "df_2015= filter_df(df_2015, [])\n",
    "df_2016= filter_df(df_2016, [])\n",
    "df_2017= filter_df(df_2017, [])\n",
    "df_2018 = filter_df(df_2018, remove_2018_2019_2020)\n",
    "df_2019 = filter_df(df_2019, remove_2018_2019_2020)\n",
    "df_2020 = filter_df(df_2020, remove_2018_2019_2020)\n",
    "data = pd.concat([df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019, df_2020])\n",
    "\n",
    "data['day_occu'] = data['day_occu'].astype(float)\n",
    "data['day_occu'] = data['day_occu'].astype(int)\n",
    "data['year_reg'] = data['year_reg'].astype(float)\n",
    "data['year_reg'] = data['year_reg'].astype(int)\n",
    "data['year_occu'] = data['year_occu'].astype(int)\n",
    "data[qual_vars] = data[qual_vars].astype(str)\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in qual_vars:\n",
    "    data[var].value_counts().plot(kind='bar')\n",
    "    plt.figure(figsize=(20,5))\n",
    "    print('\\n'+ var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean of quant vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quan_df = data[quan_vars].replace('Ignorado', -1).fillna(-1)\n",
    "quan_df[quan_vars] = quan_df[quan_vars].astype(float)\n",
    "quan_df[quan_vars] = quan_df[quan_vars].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in quan_vars:\n",
    "  serie = quan_df[quan_df[var] > 0][var]\n",
    "  display(serie.describe())\n",
    "  sns.displot(quan_df[var], kde=True)\n",
    "  print('\\033[1m' + var + '\\033[0m' + ': Kurtosis:', stats.kurtosis(serie), 'Skewness:', stats.skew(serie), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 #number of variables for heatmap\n",
    "corrmat = quan_df.corr()\n",
    "cm = np.corrcoef(corrmat.values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=quan_vars, xticklabels=quan_vars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.pairplot(quan_df, height= 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Comience  describiendo  cuantas  variables  y  observaciones  tiene  disponibles,  el tipo de cada una de las variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Haga un resumen de las variables numéricas e investigue si siguen una distribución normal y tablas de frecuencia para las variables categóricas, escriba lo que vaya encontrando. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cruce  las  variables  que  considere  que  son  las  más  importantes  para  hallar  los elementos  clave  que  lo  pueden  llevar  a  comprender  lo  que  está  causando  el problema encontrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Haga gráficos exploratorios que le de ideas del estado de los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Haga un agrupamiento (clustering) e interprete los resultados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "X_scale=sklearn.preprocessing.scale(quan_df)\n",
    "\n",
    "pyclustertend.hopkins(X_scale, len(X_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor de hopkins es de 0.004, por lo que vale la pena hacer el agrupamiento al tener datos distribuidos de manera uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyclustertend.vat(X_scale[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyclustertend.vat(quan_df[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la gráfica de codo para encontrar la cantidad óptima de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeroClusters = range(1,11)\n",
    "\n",
    "wcss = []\n",
    "# Obtenemos 10 posibles clusters\n",
    "for i in numeroClusters:\n",
    "    # Se calcula la kmean con esa cantidad de clusters\n",
    "    kmeans = cluster.KMeans(n_clusters=i)\n",
    "    kmeans.fit(X_scale)\n",
    "    # Obtenemos la inercia\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Graficando\n",
    "plt.plot(numeroClusters, wcss)\n",
    "plt.xlabel(\"Cantidad de clusters\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.title(\"Gráfico de Codo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se harán uso de 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_clusters = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luego de explorar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Describa la situación problemática que lo lleva a acotar un problema a resolver.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Enuncie un problema científico y unos objetivos preliminares.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Describa  los  datos  que  tiene  para  responder  el  problema  planteado.  Esto  incluye el  estado  en  que  encontró  el  o  los  conjuntos  de  datos  y  las  operaciones  de limpieza que le realizó, en caso de que hayan sido necesarias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Escriba unas conclusiones con los hallazgos encontrados durante el análisis \n",
    "exploratorio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a37f35004d82018ed3bf7ae7e60630ead8f0fc310ccc05d4d919854a8ecbec16"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
